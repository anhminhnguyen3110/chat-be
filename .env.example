# Application Configuration
APP_NAME=VPAura
APP_VERSION=0.1.0
DEBUG=false
ENVIRONMENT=development

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Database Configuration
DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/database_name
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# LLM API Configuration
LLM_BASE_URL=https://integrate.api.nvidia.com/v1
LLM_API_KEY=your-api-key-here
LLM_PROVIDER=openai
LLM_MODEL=qwen/qwen3-next-80b-a3b-thinking
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
LLM_FALLBACK_MODEL=qwen/qwen3-next-80b-a3b-thinking

# API Configuration
API_PREFIX=/api/v1
ALLOWED_ORIGINS=*

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=console
LOG_DIR=logs

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Guardrail Configuration
ENABLE_GUARDRAIL=true

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-neo4j-password-here

# Langfuse Configuration (Optional - Disabled by default)
# Telemetry is automatically disabled when LANGFUSE_ENABLED=true
LANGFUSE_ENABLED=false
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
LANGFUSE_SECRET_KEY=your-langfuse-secret-key
LANGFUSE_HOST=https://cloud.langfuse.com

# Checkpointer Configuration
ENABLE_CHECKPOINTER=true
CHECKPOINT_RETENTION_DAYS=30
